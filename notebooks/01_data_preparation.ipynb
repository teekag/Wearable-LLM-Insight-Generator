{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wearable Data Preparation\n",
    "\n",
    "This notebook demonstrates the process of loading, preprocessing, and feature extraction from wearable device data. We'll use the sample data files provided in the `data/raw` directory to showcase the data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Add the src directory to the path so we can import our modules\n",
    "sys.path.append('../')\n",
    "from src.data_loader import DataLoader\n",
    "from src.feature_engineer import FeatureEngineer\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data\n",
    "\n",
    "First, we'll use our `DataLoader` class to load the sample data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data loader\n",
    "data_dir = '../data/raw'\n",
    "loader = DataLoader(data_dir=data_dir)\n",
    "\n",
    "# List available files\n",
    "available_files = loader.list_available_files()\n",
    "print(f\"Available data files: {available_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HRV data\n",
    "hrv_file = 'sample_hrv_data.csv'\n",
    "hrv_data = loader.load_file(hrv_file)\n",
    "\n",
    "# Display the first few rows\n",
    "print(f\"HRV data shape: {hrv_data.shape}\")\n",
    "hrv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load activity and sleep data\n",
    "activity_sleep_file = 'sample_activity_sleep.json'\n",
    "activity_sleep_data = loader.load_file(activity_sleep_file)\n",
    "\n",
    "# Display the structure\n",
    "print(\"Activity and Sleep data structure:\")\n",
    "print(f\"- Number of activities: {len(activity_sleep_data['activities'])}\")\n",
    "print(f\"- Number of daily totals: {len(activity_sleep_data['daily_totals'])}\")\n",
    "print(f\"- Number of sleep sessions: {len(activity_sleep_data['sleep_sessions'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user goals\n",
    "goals_file = 'user_goals.json'\n",
    "user_goals = loader.load_file(goals_file)\n",
    "\n",
    "# Display user goals\n",
    "print(f\"User: {user_goals['name']}, Age: {user_goals['age']}\")\n",
    "print(\"\\nPrimary Goals:\")\n",
    "for goal in user_goals['primary_goals']:\n",
    "    print(f\"- {goal['area'].title()}: {goal['goal']} (Priority: {goal['priority']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalize and Clean Data\n",
    "\n",
    "Now we'll normalize and clean the data using our data loader's methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize HRV data\n",
    "normalized_hrv = loader.normalize_data(hrv_data, 'hrv')\n",
    "print(f\"Normalized HRV data shape: {normalized_hrv.shape}\")\n",
    "normalized_hrv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean HRV data\n",
    "cleaned_hrv = loader.clean_data(normalized_hrv)\n",
    "print(f\"Cleaned HRV data shape: {cleaned_hrv.shape}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values after cleaning:\")\n",
    "print(cleaned_hrv.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert activities to DataFrame\n",
    "activities_df = pd.DataFrame(activity_sleep_data['activities'])\n",
    "\n",
    "# Normalize activity data\n",
    "normalized_activities = loader.normalize_data(activities_df, 'activity')\n",
    "print(f\"Normalized activities data shape: {normalized_activities.shape}\")\n",
    "normalized_activities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sleep sessions to DataFrame\n",
    "sleep_df = pd.DataFrame(activity_sleep_data['sleep_sessions'])\n",
    "\n",
    "# Normalize sleep data\n",
    "normalized_sleep = loader.normalize_data(sleep_df, 'sleep')\n",
    "print(f\"Normalized sleep data shape: {normalized_sleep.shape}\")\n",
    "normalized_sleep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Segment Data by Day\n",
    "\n",
    "Next, we'll segment the data by day to prepare for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment HRV data by day\n",
    "daily_hrv = loader.segment_by_day(cleaned_hrv)\n",
    "print(f\"Number of days in HRV data: {len(daily_hrv)}\")\n",
    "\n",
    "# Display the first day's data\n",
    "first_day = list(daily_hrv.keys())[0]\n",
    "print(f\"\\nHRV data for {first_day}:\")\n",
    "daily_hrv[first_day].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment activities by day (already segmented in the original data)\n",
    "activities_by_date = {}\n",
    "for activity in activity_sleep_data['activities']:\n",
    "    date = activity['date']\n",
    "    if date not in activities_by_date:\n",
    "        activities_by_date[date] = []\n",
    "    activities_by_date[date].append(activity)\n",
    "\n",
    "print(f\"Number of days in activity data: {len(activities_by_date)}\")\n",
    "print(f\"Activities on {list(activities_by_date.keys())[0]}: {len(activities_by_date[list(activities_by_date.keys())[0]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment sleep data by day (already segmented in the original data)\n",
    "sleep_by_date = {}\n",
    "for sleep in activity_sleep_data['sleep_sessions']:\n",
    "    date = sleep['date']\n",
    "    if date not in sleep_by_date:\n",
    "        sleep_by_date[date] = []\n",
    "    sleep_by_date[date].append(sleep)\n",
    "\n",
    "print(f\"Number of days in sleep data: {len(sleep_by_date)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Features\n",
    "\n",
    "Now we'll use our `FeatureEngineer` class to extract meaningful features from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineer\n",
    "feature_eng = FeatureEngineer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HRV features for each day\n",
    "hrv_features_by_day = {}\n",
    "for date, df in daily_hrv.items():\n",
    "    hrv_features_by_day[date] = feature_eng.extract_hrv_features(df)\n",
    "\n",
    "# Display features for the first day\n",
    "first_day = list(hrv_features_by_day.keys())[0]\n",
    "print(f\"HRV features for {first_day}:\")\n",
    "for feature, value in hrv_features_by_day[first_day].items():\n",
    "    print(f\"- {feature}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract stress windows from HRV data\n",
    "stress_windows = {}\n",
    "for date, df in daily_hrv.items():\n",
    "    stress_windows[date] = feature_eng.extract_stress_windows(df)\n",
    "\n",
    "# Display stress windows for the first day\n",
    "first_day = list(stress_windows.keys())[0]\n",
    "print(f\"Stress windows for {first_day}:\")\n",
    "if stress_windows[first_day]:\n",
    "    for i, window in enumerate(stress_windows[first_day]):\n",
    "        print(f\"Window {i+1}:\")\n",
    "        print(f\"- Start: {window['start_time']}\")\n",
    "        print(f\"- End: {window['end_time']}\")\n",
    "        print(f\"- Duration: {window['duration_min']:.1f} minutes\")\n",
    "        print(f\"- Avg RMSSD: {window['avg_rmssd']:.1f}\")\n",
    "else:\n",
    "    print(\"No significant stress windows detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert activities to DataFrames by day\n",
    "activity_dfs_by_day = {}\n",
    "for date, activities in activities_by_date.items():\n",
    "    activity_dfs_by_day[date] = pd.DataFrame(activities)\n",
    "\n",
    "# Extract activity features\n",
    "activity_features_by_day = {}\n",
    "for date, df in activity_dfs_by_day.items():\n",
    "    activity_features_by_day[date] = feature_eng.extract_activity_features(df)\n",
    "\n",
    "# Display activity features for the first day\n",
    "first_day = list(activity_features_by_day.keys())[0]\n",
    "print(f\"Activity features for {first_day}:\")\n",
    "for feature, value in activity_features_by_day[first_day].items():\n",
    "    print(f\"- {feature}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sleep data to DataFrames by day\n",
    "sleep_dfs_by_day = {}\n",
    "for date, sleeps in sleep_by_date.items():\n",
    "    sleep_dfs_by_day[date] = pd.DataFrame(sleeps)\n",
    "\n",
    "# Extract sleep features\n",
    "sleep_features_by_day = {}\n",
    "for date, df in sleep_dfs_by_day.items():\n",
    "    sleep_features_by_day[date] = feature_eng.extract_sleep_features(df)\n",
    "\n",
    "# Display sleep features for the first day\n",
    "first_day = list(sleep_features_by_day.keys())[0]\n",
    "print(f\"Sleep features for {first_day}:\")\n",
    "for feature, value in sleep_features_by_day[first_day].items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"- {feature}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"- {feature}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate training load\n",
    "activity_dfs = list(activity_dfs_by_day.values())\n",
    "training_load = feature_eng.calculate_training_load(activity_dfs)\n",
    "\n",
    "print(\"Training load metrics:\")\n",
    "for metric, value in training_load.items():\n",
    "    print(f\"- {metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combine Features\n",
    "\n",
    "Now we'll combine all the features into a single dictionary for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique dates\n",
    "all_dates = set(list(hrv_features_by_day.keys()) + \n",
    "                list(activity_features_by_day.keys()) + \n",
    "                list(sleep_features_by_day.keys()))\n",
    "\n",
    "# Combine features for each day\n",
    "combined_features_by_day = {}\n",
    "for date in all_dates:\n",
    "    hrv_features = hrv_features_by_day.get(date, {})\n",
    "    activity_features = activity_features_by_day.get(date, {})\n",
    "    sleep_features = sleep_features_by_day.get(date, {})\n",
    "    \n",
    "    combined_features_by_day[date] = feature_eng.combine_features(\n",
    "        hrv_features, activity_features, sleep_features, training_load\n",
    "    )\n",
    "\n",
    "# Display combined features for the first day\n",
    "first_day = list(combined_features_by_day.keys())[0]\n",
    "print(f\"Combined features for {first_day}:\")\n",
    "print(f\"Total features: {len(combined_features_by_day[first_day])}\")\n",
    "\n",
    "# Display a few key features\n",
    "key_features = [\n",
    "    'hrv_rmssd_mean', 'activity_total_steps', 'sleep_total_sleep_hours', 'recovery_score'\n",
    "]\n",
    "for feature in key_features:\n",
    "    if feature in combined_features_by_day[first_day]:\n",
    "        value = combined_features_by_day[first_day][feature]\n",
    "        print(f\"- {feature}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Key Metrics\n",
    "\n",
    "Let's visualize some key metrics to better understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with key metrics for each day\n",
    "metrics_df = pd.DataFrame(combined_features_by_day).T\n",
    "metrics_df.index = pd.to_datetime(metrics_df.index)\n",
    "metrics_df.sort_index(inplace=True)\n",
    "\n",
    "# Select key metrics to plot\n",
    "key_metrics = [\n",
    "    'hrv_rmssd_mean', 'hrv_rmssd_min', 'hrv_rmssd_max',\n",
    "    'activity_total_steps', 'activity_active_minutes',\n",
    "    'sleep_total_sleep_hours', 'recovery_score'\n",
    "]\n",
    "\n",
    "# Filter metrics that exist in the DataFrame\n",
    "available_metrics = [m for m in key_metrics if m in metrics_df.columns]\n",
    "plot_df = metrics_df[available_metrics]\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(len(available_metrics), 1, figsize=(12, 3*len(available_metrics)))\n",
    "for i, metric in enumerate(available_metrics):\n",
    "    ax = axes[i] if len(available_metrics) > 1 else axes\n",
    "    plot_df[metric].plot(ax=ax, marker='o')\n",
    "    ax.set_title(metric.replace('_', ' ').title())\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Processed Data\n",
    "\n",
    "Finally, let's save the processed data for use in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processed data directory if it doesn't exist\n",
    "processed_dir = '../data/processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Save combined features\n",
    "with open(os.path.join(processed_dir, 'combined_features.json'), 'w') as f:\n",
    "    # Convert dates to strings for JSON serialization\n",
    "    serializable_features = {str(date): features for date, features in combined_features_by_day.items()}\n",
    "    json.dump(serializable_features, f, indent=2)\n",
    "\n",
    "# Save user goals\n",
    "with open(os.path.join(processed_dir, 'user_goals.json'), 'w') as f:\n",
    "    json.dump(user_goals, f, indent=2)\n",
    "\n",
    "print(f\"Saved processed data to {processed_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've demonstrated the complete data preparation pipeline:\n",
    "\n",
    "1. Loading raw data from CSV and JSON files\n",
    "2. Normalizing and cleaning the data\n",
    "3. Segmenting data by day\n",
    "4. Extracting meaningful features from HRV, activity, and sleep data\n",
    "5. Calculating training load metrics\n",
    "6. Combining all features into a comprehensive dataset\n",
    "7. Visualizing key metrics\n",
    "8. Saving processed data for use in insight generation\n",
    "\n",
    "This processed data will be used in subsequent notebooks to generate personalized insights using LLMs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
