{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiaTrend Data Preparation\n",
    "\n",
    "This notebook demonstrates how to load, process, and extract features from the DiaTrend dataset, which contains real-world wearable time-series data including glucose levels, insulin doses, timestamps, and user logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append('../')\n",
    "from src.data_loader import DataLoader\n",
    "from src.feature_engineer import FeatureEngineer\n",
    "\n",
    "# Set up plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and Load the DiaTrend Dataset\n",
    "\n",
    "First, we'll download the DiaTrend dataset from Zenodo and load it into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "data_loader = DataLoader()\n",
    "\n",
    "# Download DiaTrend dataset\n",
    "diatrend_file = data_loader.download_diatrend_dataset()\n",
    "\n",
    "# Load DiaTrend data\n",
    "diatrend_df = data_loader.load_diatrend_data(diatrend_file)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"DiaTrend dataset loaded with {len(diatrend_df)} records\")\n",
    "print(f\"Time range: {diatrend_df['Time'].min()} to {diatrend_df['Time'].max()}\")\n",
    "print(f\"Number of unique days: {diatrend_df['Day'].nunique()}\")\n",
    "print(\"\\nDataset columns:\")\n",
    "for col in diatrend_df.columns:\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "# Display the first few rows\n",
    "diatrend_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore the Dataset\n",
    "\n",
    "Let's explore the dataset to understand its structure and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for glucose levels\n",
    "print(\"Glucose Level Statistics:\")\n",
    "print(diatrend_df['GlucoseLevel'].describe())\n",
    "\n",
    "# Basic statistics for insulin doses\n",
    "print(\"\\nInsulin Dose Statistics:\")\n",
    "print(diatrend_df['InsulinDose'].describe())\n",
    "\n",
    "# Count non-null values in each column\n",
    "print(\"\\nNon-null values per column:\")\n",
    "print(diatrend_df.count())\n",
    "\n",
    "# Check for comments\n",
    "comment_count = diatrend_df['Comment'].notna().sum()\n",
    "print(f\"\\nNumber of entries with comments: {comment_count} ({comment_count/len(diatrend_df)*100:.2f}%)\")\n",
    "\n",
    "# Sample of comments\n",
    "if comment_count > 0:\n",
    "    print(\"\\nSample comments:\")\n",
    "    sample_comments = diatrend_df[diatrend_df['Comment'].notna()]['Comment'].sample(min(5, comment_count)).tolist()\n",
    "    for i, comment in enumerate(sample_comments, 1):\n",
    "        print(f\"{i}. {comment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Segment Data by Day\n",
    "\n",
    "Now, let's segment the data by day to analyze daily patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment data by day\n",
    "daily_data = data_loader.segment_diatrend_by_day(diatrend_df)\n",
    "\n",
    "print(f\"Segmented data into {len(daily_data)} days\")\n",
    "\n",
    "# Select a sample day for detailed analysis\n",
    "sample_day = list(daily_data.keys())[0]\n",
    "sample_df = daily_data[sample_day]\n",
    "\n",
    "print(f\"\\nSample day: {sample_day}\")\n",
    "print(f\"Number of records: {len(sample_df)}\")\n",
    "print(f\"Glucose readings: {sample_df['GlucoseLevel'].notna().sum()}\")\n",
    "print(f\"Insulin doses: {sample_df['InsulinDose'].notna().sum()}\")\n",
    "print(f\"Comments: {sample_df['Comment'].notna().sum()}\")\n",
    "\n",
    "# Plot glucose and insulin for the sample day\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot glucose levels\n",
    "ax1 = plt.subplot(211)\n",
    "glucose_data = sample_df[sample_df['GlucoseLevel'].notna()]\n",
    "ax1.plot(glucose_data['Time'], glucose_data['GlucoseLevel'], 'o-', color='blue', label='Glucose')\n",
    "ax1.set_ylabel('Glucose (mg/dL)')\n",
    "ax1.set_title(f'Glucose Levels for {sample_day}')\n",
    "ax1.axhspan(70, 180, alpha=0.2, color='green', label='Target Range')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot insulin doses\n",
    "ax2 = plt.subplot(212, sharex=ax1)\n",
    "insulin_data = sample_df[sample_df['InsulinDose'].notna()]\n",
    "ax2.stem(insulin_data['Time'], insulin_data['InsulinDose'], 'r-', label='Insulin')\n",
    "ax2.set_ylabel('Insulin (units)')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_title(f'Insulin Doses for {sample_day}')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Features from Daily Data\n",
    "\n",
    "Now, let's extract meaningful features from the daily data using our feature engineering module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineer\n",
    "feature_engineer = FeatureEngineer()\n",
    "\n",
    "# Extract features for each day\n",
    "daily_features = {}\n",
    "for day, df in daily_data.items():\n",
    "    daily_features[day] = feature_engineer.extract_diatrend_features(df)\n",
    "\n",
    "print(f\"Extracted features for {len(daily_features)} days\")\n",
    "\n",
    "# Display features for the sample day\n",
    "print(f\"\\nFeatures for {sample_day}:\")\n",
    "for feature, value in daily_features[sample_day].items():\n",
    "    print(f\"- {feature}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Glucose Volatility\n",
    "\n",
    "Let's analyze glucose volatility in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate glucose volatility for the sample day\n",
    "volatility_features = feature_engineer.calculate_glucose_volatility(sample_df)\n",
    "\n",
    "print(\"Glucose Volatility Features:\")\n",
    "for feature, value in volatility_features.items():\n",
    "    print(f\"- {feature}: {value}\")\n",
    "\n",
    "# Plot glucose rate of change\n",
    "glucose_df = sample_df[sample_df['GlucoseLevel'].notna()].copy()\n",
    "glucose_df = glucose_df.sort_values('Time')\n",
    "glucose_df['time_diff'] = glucose_df['Time'].diff().dt.total_seconds() / 60  # in minutes\n",
    "glucose_df['glucose_diff'] = glucose_df['GlucoseLevel'].diff()\n",
    "glucose_df['rate_of_change'] = glucose_df['glucose_diff'] / glucose_df['time_diff']\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "valid_roc = glucose_df['rate_of_change'].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "plt.plot(glucose_df['Time'][1:], valid_roc, 'o-', color='purple')\n",
    "plt.axhline(y=0, color='gray', linestyle='--')\n",
    "plt.ylabel('Rate of Change (mg/dL per minute)')\n",
    "plt.title(f'Glucose Rate of Change for {sample_day}')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Meal Responses\n",
    "\n",
    "Let's identify potential meals and analyze glucose responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract meal-related features\n",
    "meal_features = feature_engineer.extract_meal_related_features(sample_df)\n",
    "\n",
    "print(\"Meal-Related Features:\")\n",
    "for feature, value in meal_features.items():\n",
    "    print(f\"- {feature}: {value}\")\n",
    "\n",
    "# Identify potential meal times\n",
    "meal_indicators = ['meal', 'breakfast', 'lunch', 'dinner', 'eating', 'food', 'carbs', 'snack']\n",
    "meal_rows = sample_df[sample_df['Comment'].str.lower().str.contains('|'.join(meal_indicators), na=False)]\n",
    "\n",
    "# Also consider insulin doses as potential meal indicators\n",
    "insulin_rows = sample_df[(sample_df['InsulinDose'] > 0) & sample_df['InsulinDose'].notna()]\n",
    "meal_rows = pd.concat([meal_rows, insulin_rows]).drop_duplicates()\n",
    "\n",
    "# Plot glucose around meal times\n",
    "if len(meal_rows) > 0:\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    for i, (_, meal_row) in enumerate(meal_rows.iterrows(), 1):\n",
    "        if i > 3:  # Limit to 3 meals for clarity\n",
    "            break\n",
    "            \n",
    "        meal_time = meal_row['Time']\n",
    "        \n",
    "        # Get glucose values 2 hours before and after meal\n",
    "        window_start = meal_time - pd.Timedelta(hours=2)\n",
    "        window_end = meal_time + pd.Timedelta(hours=2)\n",
    "        \n",
    "        meal_window = sample_df[(sample_df['Time'] >= window_start) & \n",
    "                               (sample_df['Time'] <= window_end) & \n",
    "                               sample_df['GlucoseLevel'].notna()]\n",
    "        \n",
    "        if len(meal_window) < 2:\n",
    "            continue\n",
    "            \n",
    "        ax = plt.subplot(3, 1, i)\n",
    "        \n",
    "        # Convert to minutes relative to meal time\n",
    "        meal_window['minutes'] = (meal_window['Time'] - meal_time).dt.total_seconds() / 60\n",
    "        \n",
    "        # Plot glucose\n",
    "        ax.plot(meal_window['minutes'], meal_window['GlucoseLevel'], 'o-', color='blue')\n",
    "        \n",
    "        # Add meal time marker\n",
    "        ax.axvline(x=0, color='red', linestyle='--', label='Meal Time')\n",
    "        \n",
    "        # Add comment if available\n",
    "        comment = meal_row.get('Comment', '')\n",
    "        insulin = meal_row.get('InsulinDose', 0)\n",
    "        title = f\"Meal at {meal_time.strftime('%H:%M')}\"\n",
    "        if pd.notna(insulin) and insulin > 0:\n",
    "            title += f\" (Insulin: {insulin} units)\"\n",
    "        if pd.notna(comment) and comment:\n",
    "            title += f\"\\nComment: {comment}\"\n",
    "            \n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Minutes relative to meal')\n",
    "        ax.set_ylabel('Glucose (mg/dL)')\n",
    "        ax.grid(True)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No clear meal times identified for this day.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Comment Sentiment\n",
    "\n",
    "Let's analyze the sentiment and tags in user comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract comment sentiment features\n",
    "comment_features = feature_engineer.analyze_comment_sentiment(sample_df)\n",
    "\n",
    "print(\"Comment Analysis Features:\")\n",
    "for feature, value in comment_features.items():\n",
    "    print(f\"- {feature}: {value}\")\n",
    "\n",
    "# Display all comments for the day\n",
    "comments = sample_df[sample_df['Comment'].notna()]\n",
    "if len(comments) > 0:\n",
    "    print(\"\\nAll comments for the day:\")\n",
    "    for _, row in comments.iterrows():\n",
    "        print(f\"[{row['Time'].strftime('%H:%M')}] {row['Comment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Processed Data\n",
    "\n",
    "Finally, let's save the processed data and extracted features for use in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processed directory if it doesn't exist\n",
    "processed_dir = '../data/processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Save daily features\n",
    "with open(os.path.join(processed_dir, 'diatrend_daily_features.json'), 'w') as f:\n",
    "    json.dump(daily_features, f, indent=2)\n",
    "\n",
    "# Create sample user goals\n",
    "user_goals = {\n",
    "    \"name\": \"Alex\",\n",
    "    \"primary_goals\": [\n",
    "        {\"area\": \"glucose\", \"goal\": \"Reduce post-meal glucose spikes\"},\n",
    "        {\"area\": \"insulin\", \"goal\": \"Optimize insulin timing for better glucose control\"},\n",
    "        {\"area\": \"lifestyle\", \"goal\": \"Understand how exercise affects glucose levels\"}\n",
    "    ],\n",
    "    \"diabetes_type\": \"Type 1\",\n",
    "    \"target_glucose_range\": \"70-180 mg/dL\"\n",
    "}\n",
    "\n",
    "# Save user goals\n",
    "with open(os.path.join(processed_dir, 'diatrend_user_goals.json'), 'w') as f:\n",
    "    json.dump(user_goals, f, indent=2)\n",
    "\n",
    "print(\"Saved processed data and features to:\")\n",
    "print(f\"- {os.path.join(processed_dir, 'diatrend_daily_features.json')}\")\n",
    "print(f\"- {os.path.join(processed_dir, 'diatrend_user_goals.json')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "In this notebook, we've demonstrated how to:\n",
    "\n",
    "1. Download and load the DiaTrend dataset\n",
    "2. Explore the dataset structure and content\n",
    "3. Segment the data by day\n",
    "4. Extract meaningful features from daily data\n",
    "5. Analyze glucose volatility\n",
    "6. Identify and analyze meal responses\n",
    "7. Analyze comment sentiment and tags\n",
    "8. Save processed data for use in other notebooks\n",
    "\n",
    "These processed features will be used in subsequent notebooks to generate personalized insights using LLMs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
